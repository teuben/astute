%$Id$
\documentclass{report}
\title{ADMIT XML Design}
\author{Marc Pound, Peter Teuben, Doug Friedel}
\date{\today}
\begin{document}
\maketitle

\section{Overview}

For each science project ADMIT runs a series of ``admit tasks'', which
are essentially beefed up CASA tools/tasks, and produce Basic Data
Products (BDP).  ADMIT provides a wrapper around these tasks
(CASA tasks, but with some extra baggage to make it fit within the pipeline
and have a persistent state within the pipeline as well for re-use by
the user later on).

Once users have downloaded the data, they can preview the work the pipeline
has created for them. They will also be able to re-run
selected portions of the ADMIT pipeline from either the (casapy)
commandline, or a (casa) GUI, and compare and improve upon the
pipeline produced results. ADMIT produces Basic Data Product (BDP), in
addition to the existing Alma Data Products (ADP)\footnote{Examples of
ADP's in a project are the Raw Visibility Data (in ASDM format) and
the Science Data Cubes (in FITS format) for each source and each
band}

Virtual projects can be defined, and ADMIT be used to steer and control
how to run on individual projects and sources, after which selected
results can be datamined 

\section{This Document}

Below we first outline the core XML components of ADMIT, followed by
the python interface, the XML I/O interface, and an ADMIT GUI.

\section{Guiding Principles}
The XML structure should be complete enough to capture proposed use cases,
but not so restrictive that it precludes future use cases. To that end, a
limited hierarchy is desirable, with basic ``objects" that can be contained
within one another but are not {\it defined} within one another.  However, we
do need to follow what we understand to be the basic hierarchical structure
that the archive produces Project$\rightarrow$Source$\rightarrow$Bands.
We argue it is not necessary to expose the Project container to
the user, e.g. in the case of a data mining operation that spans multiple
projects. The science is in the sources not the project. To that end, the
Project container is extremely thin: it contains only the identificiation
code, everything else is inside source containers.

\subsection{Elements vs. Attributes}
We follow the principal that data go in elements and metadata about
elements go in attributes.   Thus rather than

\begin{verbatim}
<project name="c0123">  
\end{verbatim}

\noindent we use 

\begin{verbatim}
<project>
    <name>c0123</name>
\end{verbatim}

\noindent However, if project name is an element we want to
be read-only (ADMIT user cannot change it), we use an attribute.

\begin{verbatim}
<project>
  <name readonly="true">c0123</name>
\end{verbatim}

\noindent Or if an element has a fixed type, we use an attribute:
\begin{verbatim}
<myelement type="float">
\end{verbatim}

\section{Basic Data Products}

The pipeline results and outputs of ADMIT tasks are described as 
Basic Data Products. A BDP may contain computed or harvested information
as well as point to an external resource, such as an image file.
%% Peter - What do you mean by this?
Only the smaller portions of the BDP can be found
in the admit.zip file, others will have to be recreated. 
%
Examples of BDP (both exported and recreatable) are
ADMIT pipeline. 

\begin{enumerate}
\item
Summary of the meta data, as much as is needed for the ADMIT pipeline.
\item
Cube Statistics: a simple table of min, max, mean, median etc. for each plane
\item
Line List: a list of all lines detected in a band, but there is also a bandmerged version
\item
Line Cube: foreach line from the Line List there will be a data cube extracted from the
band cube.  (the cube itself will not be exported)
\item
Moment: simple moment maps (0,1,2). These will be also be exported as JPEG.
\item
PeakSpectrum: for each line cube a spectrum through the cube at the peak in moment-0 is given
\item
Feature List: for each line cube a list of features (clumps, blobs, etc.) is saved in tabular format.
\item 
Overlap Integral: combining all Mom0 maps, an overlap integral map is created.
\end{enumerate}

\noindent All BDP instances have the following structure:

\begin{verbatim}
BDP
  name 
  data element 1
  data element 2
  ...
  data element N
  task
  dependencies
\end{verbatim}

\noindent where {\it name} is the descriptive name (``summary,''
``linelist''), {\it data elements} are harvested information, computed 
values, tables, or pointers to images, {\it task} is the ADMIT/CASA 
task used to create this BDP with all all task parameter values specified,
and {\it dependencies} are other BDPs upon which this one depends. 
If a dependency BDP changes, this one should be recomputed.


\section{Basic XML Types}

Here we outline the basic XML types of which the Basic Data Products
may be composed, with an example but not exhaustive list of elements for each.
All tables will be stored in VOTable format.
\begin{verbatim}

<project>
    <name>
</project>

<source>
    <name></name>
    <coordinate>
        <crvalN>
        <ctypeN>
    </coordinate>
    <equinox>
    <type> [galactic, extragalactic, etc]
</source>

   <statistics>
%% One can have multiple areas over which statistics are measured.
%% NB: Does casa multiple boxes print two stats or one?
%% Are we supporting polygons?
        <region>
            <number>
            %% If polygonal, this might become a list of vertices.
            <blc>
            <trc>
            <startchannel>
            <endchannel>
            <mean>
            <max>
            <rms>
            <clip>
        </region>
   </statistics>

<spectrum>
   <start freq>
   <start vel>
   <dvel>
   <nchan>  % perhaps VOtable encapsuulates number of channels already
   <statistics> </statistics> %% as above
   <votable>
</spectrum>

<image>
   <URI>
   <type> [data or thumbnail]
   <description> [moment zero, moment one, spectral cutout, full cube. ??] 
   <naxisN>
   <crpixN>
   <crvalN>
   <ctypeN>
   <statistics></statistics>
</image>
\end{verbatim}

We expect the ADMIT task will defined exactly as a CASA task, for which the XML
representation is already defined as follows:

\begin{verbatim}
<task type="function" name="foobar" category="fumbar">
    <shortdescription>
    <description>
    <input>
    <param>
        <description>
        <any>
        <value>
    <returns>
    <example>
</task>  

\end{verbatim}

Using these types, a BDP XML definition takes shape:

\begin{verbatim}
<BDPName type="bdp">
   <element1>
   <element2>
   ...
   <elementN>
   <task>
   <dependencies>
</BDPName>

\end{verbatim}

\noindent For example, a moment-1 map might look like:

\begin{verbatim}
<moment type="bdp">
   <integral>1</integral>
   <description>velocity centroid</description>
   <method>clip</method>
   <image>...</image>  % e.g. the FITS image
   <image>...</image>  % e.g. the JPEG image
   <task type="function" name="moment" category="imagefu">
        <param type="float" name="clip">
           <value>0.1</value>
        </param>
        <param type="float" name="vmin">
           <value> -123.0</value>
        </param>
        <param type="float" name="vmax">
           <value> 234.0</value>
        </param>
   </task>
   <dependencies>linecube</dependencies>
   <date>YYYY-MM-DD HH:MM:SS</date>
</moment>

\end{verbatim}
 

\section{XML Overview}
Without the cumbersome XML syntax, but simply using indentation, this is
an overview of the XML tree that admit.zip will contain

\newpage

\footnotesize
\begin{verbatim}

 Project(name)[NP]
    Summary
       <atask name=at_summary>
    Source(name)[NS]
       Summary
           ra,dec,vlsr,...
           <atask name=at_summary>
       Band(number)[NB]
           URI:im
           Summary
              FreqMin,FreqMax,FreqStep
           CubeStats
              VoTable:tab
              <atask name=at_cubestats>
              <dep>
                 URI:im
           PosVelSlice
              URI:im
              file:jpg
              <atask name=at_pv>
                 <dep>
                 URI:im
           LineList
              VoTable:tab
              <atask name=at_band2line>
              <dep>
                CubeStats
        LineList
           votable:tab
           <atask name=at_linemerge>
           <dep>
             band[NB].LineList
        Continuum(name)
           URI:im
           file.jpg
           <atask name=at_continuum>
           <dep>
              Band(this)
        Line(name)[NL]
           LineCube
              URI:im
              <atask name=at_reframe>
              <dep>
                LineList
           RMS (since cubestats can differ per channel)
           Mom0
              URI:im
              file:jpg
              <atask name=at_moment>
              <dep>
                LineCube
           Mom1
           Mom2
           PeakSpectrum
              VoTable:tab
              <summary>
                Peak, RMS, V0, FWHM, SdV
              <atask name=at_spectrum>
              <dep>
                LineCube
           IntegratedSpectrum
              VoTable:tab
              <summary>
                Peak, RMS, V0, FWHM, SdV
              <atask name=at_spectrum>
              <dep>
                LineCube


\end{verbatim}
\normalsize

\newpage

The dependencies might even fit in a Makefile, viz. (using the P/S/B and P/S/L hierarchy)


\footnotesize
\begin{verbatim}

p1_s1_l1_mom0:          p1_s1_l1_linecube

p1_s1_l1_linecube:      p1_s1_linelist p1_s1_b1

p1_s1_linelist:         p1_s1_b1_linelist p1_s1_b2_linelist p1_s1_b3_linelist p1_s1_b4_linelist
                        at_linemerge

p1_s1_b1_linelist:      p1_s1_b1
                        at_band2line

p1_s1_b1:               file:im
                        at_archive(p1,s1,b1)

p1_summary:
                        at_summary
        
\end{verbatim}
\normalsize

\subsection{Virtual Project}

The virtual projects defined by the user will have their own xml
structure, not saved in the admit.zip file(s), but in a separate xml
file. This file will have links to the members of the virtual project
(or may import them into its own file, this should be discussed). The
virtual project will contain nodes for dividing up the individual
parts so that they can be grouped by the user or ADMIT, for further
analysis. A sample xml structure follows:


\begin{verbatim}
<project type="virtual">
    <group name="name1">
    	<common item: cutoff, molecule, etc>
    	<member>
    		<file name="file name"/>
    	</member>
    	...
    </group>
    ...
</project>
\end{verbatim}


\section{Python}

Since CASA interfaces are all in python, most -- if not all -- of
ADMIT will be in python. Some adaptations to casa routines will
likely be needed, and this may invoke some changes to the CASA
C++ core code.

\subsection{XML I/O and manipulation layer}

A choice between SAX and DOM parsing of XML will have to be made.
SAX appears to be the favorite, based on much smaller memory
footprint and more flexible parsing.




{\it xml i/o and manipulation layer -- this is to standardize
the interaction with the xml for all higher level
routine and to enable and simplity the xml stucture
that we decide upon in the xml definitions
Marc and Peter might meet on this level -- from the
xml definitions below and the python layer above...}



\subsection{Python layer}

This is the layer that enables the interaction with
CASA and the pipeline. Is there really a clear distinction 
between this and the previous section on XML I/O, which
all happen in python?

The basic scheme of ADMIT is to open a project, compute a set of
tasks, in a serial fashion, and close the project. This is independent
from being in the archive, or being a user re-asessing the scientific
value of the datasets. Especially in the latter case, decisions are
made based on interactive use with the pipeline. In particular it will
be important to be able to compare basic data products of different
versions of the pipeline, for example, the velocity field of a line is
to be compared between two different methods of computing the moments.

\begin{enumerate}

\item
Opening a (single) project. The first mode is where there no {\tt admit.zip} 
present yet, and everything needs to be initialized: find
the sources, the number of bands per source, and the variables
describing each source/band (e.g. ra,dec,vlsr,freq ranges etc.). A
basic XML needs to be set up.  No other tasks will be run in the
pipeline, although this summary could be seen as the default
initialization task.


\item
(Re)opening from an existing XML.  All structures will need to be 
intialized. Status and Dependency list of the various data products
need to be set.

\item
Opening from an existing ZIP. This is very similar to the previous
item, but must also create a directory structure hierarchy and 
populate basic data products.

\item
(Re)compute a basic data product. The dependencies need to be reviewed
(multiple are possible), as well as allow to bypass recomputing these
if not desired?  The method needs to be selected, parameters for this
method set, as well as the style of execution (in theory, we only
allow casa execution, but basic unix packages such as MIRIAD could 
also be an option).  When all is set, the task can be executed, so the
BDP is created.

\item
Save a project:  either the ADMIT python object is serialized into XML, 
or in addition all associated allowed basic data products 
are wrapped in a single {\tt admit.zip} file. Not all data products
can be wrapped in {\tt admit.zip}. For example Line Cubes are not, given
their size. Moment maps have both JPG and FITS versions, 


\end{enumerate}

\section{Methods}

\subsection{CubeStats}

The primary idea of CubeStats is to provide initial guidance for line
identification, or even the line identification itself. For each
channel it tabulates the Min, Max, RMS, Mean and Median.

\subsection{LineList}

A LineList is a simple table, tabulating which lines are present
in the cube, and some idea how strong the line is. Something like
{\it Signal/(Signal+Noise)}, some number between 0 (unlikely) or 1 
(very likely).


\subsection{PVcorr}

A position-velocity diagram is needed, which can be used to more
accurately determine the frequencies of lines.  To create a good
PV diagram, a position angle is needed, which can be obtained
by summing up all emission above some conservative 3 or 4 times
the RMS, and using a moment of inertia in the resulting summed
emission map.  When the axis ratio of this emission is round
enough, an XYVcorr might give better S/N.  PosVelSlice

\subsection{XYVcorr}

This is the 3D extension of the 2D PVcorr method. In theory should be
more sensitive/accurate, if the emission is really not along some
major axis. This has not been well tested.



\section{GUI}


\subsection{API for tool and GUI}

{\it these are the API for actual tools that do the
work and the GUI. What does the interface look like?
How does the GUI interact with the lower layers? How
can the GUI interact with CASA Viewer?}

\section{Use Cases}

\subsection{Archive}

The first case covers the first goal for ADMIT: produce an {\tt
  admit.zip} for a given project.  A project contains one or more
sources, and for each source there will be (at least for ALMA) 4 image
data cubes, in FITS format. This will produce all the Basic Data
products and a descriptive {\tt admit.xml} file and add this as 
{\tt admit.zip} to the archive.



\subsection{First Look}

The next case covers a user that has gone to his/her project on the archive,
and downloaded the {\tt admit.zip} file. The ADMIT environment in casapy
will then either print to screen a GUI outlining all BDPs present, or
allow looping over and visualizing them via python methods. There is no
essential computing needed in this step.

\subsection{Rerun Pipeline}

After a first look, the user may be unhappy that a certain obvious line
was not added to the line cataloge (LineList). Or may want to recreate
moment maps based on a lower clip level, or a whole new method of
computing moments. In the user interface each BDP has an
interaction popup by which its input methods and parameters can be changed.

\subsection{Virtual Projects}

In this more advanced case, the user selects a number of sources from one
or more projects in a virtual ADMIT container. Any of the basic ADMIT procedures
can now be re-run and/or reviewed, but looped over the selected sources.
Users can write their own procedures,
and store persistent data back into {\tt admit.zip}. ADMIT has interfaces
using Python to extract numbers and Python arrays out of admit.zip, and thereby
allow for flexible data mining, linked data plotting etc.

%\subsection{Virtual Project Data Mining}
%
%One of the novel ways in which users can interact with ADMIT is the
%virtual project.  A series of projects (really project/source combinations)
%can be selected for further work and data mined.
%
%Setup a virtual project (VP) based on either all P's that have valid azip's, or use a complex query that goes into each Project and either selects or deselects.
%Manual creation is perfectly ok as well.
%
%We need some use cases here. 
%    - select based on a specific line (L) present
%    - select based on a source name
%    - select based on a previously set user supplied keyword (on what level?)
%
%VP needs to have some record how it was created
%  
%Re-run one more more VPs based on a procedure established in one P ?
%
%Data Mining operations in VPs?
%
%- acumulate things you did in a P into an VP (e.g. clump spectrum to gain statistics)
%
%- extract things from a P (or do we need to distinguish P from P/S or P/S/B or P/S/L)
%and stuff them in Python data structures for any plotting or linked data analysis/vis
%MatplotLib (?Should we use GLUE as our standard example to visualize?)
%



\end{document}
